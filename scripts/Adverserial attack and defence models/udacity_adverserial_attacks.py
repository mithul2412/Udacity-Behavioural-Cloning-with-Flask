# -*- coding: utf-8 -*-
"""Udacity_Adverserial_Attacks

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q-JzehS9Wvt6BMazZBO3Q_stbLA1uuJG
"""

!git clone https://github.com/rslim087a/track

!ls track

!pip3 install imgaug

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import keras
from keras.models import Sequential
from keras.optimizers import Adam
from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from imgaug import augmenters as iaa
import cv2
import pandas as pd
import ntpath
import random

datadir = 'track'
columns = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']
data = pd.read_csv(os.path.join(datadir, 'driving_log.csv'), names = columns)
pd.set_option('display.max_colwidth', -1)
data.head()

def path_leaf(path):
  head, tail = ntpath.split(path)
  return tail
data['center'] = data['center'].apply(path_leaf)
data['left'] = data['left'].apply(path_leaf)
data['right'] = data['right'].apply(path_leaf)
data.head()

num_bins = 25
samples_per_bin = 400
hist, bins = np.histogram(data['steering'], num_bins)
center = (bins[:-1]+ bins[1:]) * 0.5
plt.bar(center, hist, width=0.05)
plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin, samples_per_bin))

print('total data:', len(data))
remove_list = []
for j in range(num_bins):
  list_ = []
  for i in range(len(data['steering'])):
    if data['steering'][i] >= bins[j] and data['steering'][i] <= bins[j+1]:
      list_.append(i)
  list_ = shuffle(list_)
  list_ = list_[samples_per_bin:]
  remove_list.extend(list_)

print('removed:', len(remove_list))
data.drop(data.index[remove_list], inplace=True)
print('remaining:', len(data))

hist, _ = np.histogram(data['steering'], (num_bins))
plt.bar(center, hist, width=0.05)
plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin, samples_per_bin))

print(data.iloc[1])
def load_img_steering(datadir, df):
  image_path = []
  steering = []
  for i in range(len(data)):
    indexed_data = data.iloc[i]
    center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]
    image_path.append(os.path.join(datadir, center.strip()))
    steering.append(float(indexed_data[3]))
    # left image append
    image_path.append(os.path.join(datadir,left.strip()))
    steering.append(float(indexed_data[3])+0.15)
    # right image append
    image_path.append(os.path.join(datadir,right.strip()))
    steering.append(float(indexed_data[3])-0.15)
  image_paths = np.asarray(image_path)
  steerings = np.asarray(steering)
  return image_paths, steerings

image_paths, steerings = load_img_steering(datadir + '/IMG', data)

# X_train, X_valid, y_train, y_valid = train_test_split(image_paths, steerings, test_size=0.2, random_state=6)
# print('Training Samples: {}\nValid Samples: {}'.format(len(X_train), len(X_valid)))

X_temp, X_test, y_temp, y_test = train_test_split(image_paths, steerings, test_size=0.2, random_state=6)
X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.125, random_state=6) # 0.125 x 0.8 = 0.1
print('Training Samples: {}\nValidation Samples: {}\nTesting Samples: {}'.format(len(X_train), len(X_valid), len(X_test)))

fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].hist(y_train, bins=num_bins, width=0.05, color='blue')
axes[0].set_title('Training set')
axes[1].hist(y_valid, bins=num_bins, width=0.05, color='red')
axes[1].set_title('Validation set')

def zoom(image):
  zoom = iaa.Affine(scale=(1, 1.3))
  image = zoom.augment_image(image)
  return image

image = image_paths[random.randint(0, 1000)]
original_image = mpimg.imread(image)
zoomed_image = zoom(original_image)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image')

axs[1].imshow(zoomed_image)
axs[1].set_title('Zoomed Image')

def pan(image):
  pan = iaa.Affine(translate_percent= {"x" : (-0.1, 0.1), "y": (-0.1, 0.1)})
  image = pan.augment_image(image)
  return image
image = image_paths[random.randint(0, 1000)]
original_image = mpimg.imread(image)
panned_image = pan(original_image)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image')

axs[1].imshow(panned_image)
axs[1].set_title('Panned Image')

def img_random_brightness(image):
    brightness = iaa.Multiply((0.2, 1.2))
    image = brightness.augment_image(image)
    return image

image = image_paths[random.randint(0, 1000)]
original_image = mpimg.imread(image)
brightness_altered_image = img_random_brightness(original_image)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image')

axs[1].imshow(brightness_altered_image)
axs[1].set_title('Brightness altered image ')

def img_random_flip(image, steering_angle):
    image = cv2.flip(image,1)
    steering_angle = -steering_angle
    return image, steering_angle
random_index = random.randint(0, 1000)
image = image_paths[random_index]
steering_angle = steerings[random_index]


original_image = mpimg.imread(image)
flipped_image, flipped_steering_angle = img_random_flip(original_image, steering_angle)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(original_image)
axs[0].set_title('Original Image - ' + 'Steering Angle:' + str(steering_angle))

axs[1].imshow(flipped_image)
axs[1].set_title('Flipped Image - ' + 'Steering Angle:' + str(flipped_steering_angle))

def random_augment(image, steering_angle):
    image = mpimg.imread(image)
    if np.random.rand() < 0.5:
      image = pan(image)
    if np.random.rand() < 0.5:
      image = zoom(image)
    if np.random.rand() < 0.5:
      image = img_random_brightness(image)
    if np.random.rand() < 0.5:
      image, steering_angle = img_random_flip(image, steering_angle)

    return image, steering_angle

ncol = 2
nrow = 10

fig, axs = plt.subplots(nrow, ncol, figsize=(15, 50))
fig.tight_layout()

for i in range(10):
  randnum = random.randint(0, len(image_paths) - 1)
  random_image = image_paths[randnum]
  random_steering = steerings[randnum]

  original_image = mpimg.imread(random_image)
  augmented_image, steering = random_augment(random_image, random_steering)

  axs[i][0].imshow(original_image)
  axs[i][0].set_title("Original Image")

  axs[i][1].imshow(augmented_image)
  axs[i][1].set_title("Augmented Image")

def img_preprocess(img):
    img = img[60:135,:,:]
    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)
    img = cv2.GaussianBlur(img,  (3, 3), 0)
    img = cv2.resize(img, (200, 66))
    img = img/255
    return img

image = image_paths[100]
original_image = mpimg.imread(image)
preprocessed_image = img_preprocess(original_image)

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()
axs[0].imshow(original_image)
axs[0].set_title('Original Image')
axs[1].imshow(preprocessed_image)
axs[1].set_title('Preprocessed Image')

def batch_generator(image_paths, steering_ang, batch_size, istraining):

  while True:
    batch_img = []
    batch_steering = []

    for i in range(batch_size):
      random_index = random.randint(0, len(image_paths) - 1)

      if istraining:
        im, steering = random_augment(image_paths[random_index], steering_ang[random_index])

      else:
        im = mpimg.imread(image_paths[random_index])
        steering = steering_ang[random_index]

      im = img_preprocess(im)
      batch_img.append(im)
      batch_steering.append(steering)
    yield (np.asarray(batch_img), np.asarray(batch_steering))

x_train_gen, y_train_gen = next(batch_generator(X_train, y_train, 1, 1))
x_valid_gen, y_valid_gen = next(batch_generator(X_valid, y_valid, 1, 0))

fig, axs = plt.subplots(1, 2, figsize=(15, 10))
fig.tight_layout()

axs[0].imshow(x_train_gen[0])
axs[0].set_title('Training Image')

axs[1].imshow(x_valid_gen[0])
axs[1].set_title('Validation Image')

def nvidia_model():
  model = Sequential()
  model.add(Convolution2D(24, kernel_size=(5,5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))
  model.add(Convolution2D(36, kernel_size=(5,5), strides=(2, 2), activation='elu'))
  model.add(Convolution2D(48, kernel_size=(5,5), strides=(2, 2), activation='elu'))
  model.add(Convolution2D(64, kernel_size=(3,3), activation='elu'))

  model.add(Convolution2D(64, kernel_size=(3,3), activation='elu'))

  model.add(Flatten())

  model.add(Dense(100, activation = 'elu'))

  model.add(Dense(50, activation = 'elu'))

  model.add(Dense(10, activation = 'elu'))

  model.add(Dense(1))

  optimizer = Adam(lr=1e-3)
  model.compile(loss='mse', optimizer=optimizer)
  return model

model = nvidia_model()
print(model.summary())

# history = model.fit_generator(batch_generator(X_train, y_train, 100, 1),
#                                   steps_per_epoch=300,
#                                   epochs=10,
#                                   validation_data=batch_generator(X_valid, y_valid, 100, 0),
#                                   validation_steps=200,
#                                   verbose=1,
#                                   shuffle = 1)

history = model.fit_generator(batch_generator(X_train, y_train, 100, 1),
                              steps_per_epoch=300,
                              epochs=10,
                              validation_data=batch_generator(X_valid, y_valid, 100, 0),
                              validation_steps=200,
                              verbose=1,
                              shuffle=1)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('Loss')
plt.xlabel('Epoch')

model.save('model.h5')

# from google.colab import files
# files.download('model.h5')

from keras.models import load_model
model = load_model('model.h5')

# Evaluation on Test Data
test_generator = batch_generator(X_test, y_test, 100, 0)
test_steps = len(X_test) // 100

# Calculating the metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

y_true = []
y_pred = []

for i in range(test_steps):
    x_batch, y_batch = next(test_generator)
    predictions = model.predict(x_batch)

    y_true.extend(y_batch)
    y_pred.extend(predictions.reshape(-1))

mse = mean_squared_error(y_true, y_pred)
mae = mean_absolute_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'Mean Absolute Error: {mae}')
print(f'R^2 Score: {r2}')

!pip install cleverhans

import tensorflow as tf
from cleverhans.tf2.attacks import fast_gradient_method

# # Select a random subset of 100 images from the test data
# random_indices = random.sample(range(len(X_test)), 100)
# subset_x_test = [X_test[i] for i in random_indices]
# subset_y_test = [y_test[i] for i in random_indices]

# Use the entire test dataset
subset_x_test = X_test
subset_y_test = y_test

# Preprocess the images
adv_images = [img_preprocess(mpimg.imread(img_path)) for img_path in subset_x_test]
adv_images = np.array(adv_images)

# Generate adversarial examples
epsilon = 0.3  # Per3turbation limit
adv_examples = fast_gradient_method.fast_gradient_method(model, adv_images, epsilon, np.inf, targeted=False)

# Evaluate model on adversarial examples
adv_predictions = model.predict(adv_examples)

# Calculate metrics on adversarial examples
adv_mse = mean_squared_error(subset_y_test, adv_predictions)
adv_mae = mean_absolute_error(subset_y_test, adv_predictions)
adv_r2 = r2_score(subset_y_test, adv_predictions)

print(f'Mean Squared Error on Adversarial Examples: {adv_mse}')
print(f'Mean Absolute Error on Adversarial Examples: {adv_mae}')
print(f'R^2 Score on Adversarial Examples: {adv_r2}')

# Predictions on original images
original_predictions = model.predict(adv_images)

# Visualization of original vs. adversarial examples
num_examples = 5  # You can adjust this value
plt.figure(figsize=(20, num_examples * 6))
for i in range(num_examples):
    # Original image
    plt.subplot(num_examples, 2, i * 2 + 1)
    plt.imshow(adv_images[i])
    plt.title(f'Original Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {original_predictions[i][0]}')

    # Adversarial image
    plt.subplot(num_examples, 2, i * 2 + 2)
    plt.imshow(adv_examples[i])
    plt.title(f'Adversarial Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {adv_predictions[i][0]}')

plt.tight_layout()
plt.show()

from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method

# Preprocess the images
adv_images = [img_preprocess(mpimg.imread(img_path)) for img_path in subset_x_test]
adv_images = np.array(adv_images)

# Generate adversarial examples
# epsilon = 0.25  # Perturbation limit

# Generate targeted adversarial examples to increase the steering angle

# Make predictions on the original images
# original_preds = model.predict(adv_images)

# Calculate targets: Increase predictions by a certain amount
target = np.clip(original_preds + 0.5, -1, 1)  # Increase steering angle by 0.5

# Custom loss function for regression FGSM
def custom_loss(labels, logits):
    return tf.keras.losses.mean_squared_error(labels, logits)

# # Calculate adversarial examples using custom loss
# perturbations = fast_gradient_method(model, adv_images, epsilon, np.inf, loss_fn=custom_loss, y=target)
# perturbations = np.clip(perturbations, -epsilon, epsilon)
# adv_examples = adv_images + perturbations
# adv_examples = np.clip(adv_examples, 0, 1)

# # Evaluate model on adversarial examples
# adv_predictions = model.predict(adv_examples)

# # Calculate metrics on adversarial examples
# adv_mse = mean_squared_error(subset_y_test, adv_predictions)
# adv_mae = mean_absolute_error(subset_y_test, adv_predictions)
# adv_r2 = r2_score(subset_y_test, adv_predictions)

# print(f'Mean Squared Error on Adversarial Examples: {adv_mse}')
# print(f'Mean Absolute Error on Adversarial Examples: {adv_mae}')
# print(f'R^2 Score on Adversarial Examples: {adv_r2}')

# # Predictions on original images
# original_predictions = model.predict(adv_images)

# # Visualization of original vs. adversarial examples
# num_examples = 5  # You can adjust this value
# plt.figure(figsize=(20, num_examples * 6))
# for i in range(num_examples):
#     # Original image
#     plt.subplot(num_examples, 2, i * 2 + 1)
#     plt.imshow(adv_images[i])
#     plt.title(f'Original Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {original_predictions[i][0]}')

#     # Adversarial image
#     plt.subplot(num_examples, 2, i * 2 + 2)
#     plt.imshow(adv_examples[i])
#     plt.title(f'Adversarial Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {adv_predictions[i][0]}')

# plt.tight_layout()
# plt.show()
epsilons = np.arange(0.1, 0.3, 0.02)  # This will give [0.1, 0.14, 0.18, ... , 0.28]
mse_values = []
mae_values = []
r2_values = []

for eps in epsilons:
    # Generate adversarial examples using FGSM for current epsilon
    perturbations = fast_gradient_method(model, adv_images, eps, np.inf, loss_fn=custom_loss, y=target)
    perturbations = np.clip(perturbations, -eps, eps)
    adv_examples = adv_images + perturbations
    adv_examples = np.clip(adv_examples, 0, 1)

    # Evaluate model on adversarial examples
    adv_predictions = model.predict(adv_examples)

    # Calculate metrics on adversarial examples
    mse_values.append(mean_squared_error(subset_y_test, adv_predictions))
    mae_values.append(mean_absolute_error(subset_y_test, adv_predictions))
    r2_values.append(r2_score(subset_y_test, adv_predictions))

# Plotting
plt.figure(figsize=(15, 5))

# MSE Plot
plt.subplot(1, 3, 1)
plt.plot(epsilons, mse_values, marker='o')
plt.title('Mean Squared Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Squared Error')
plt.xticks(epsilons)

# MAE Plot
plt.subplot(1, 3, 2)
plt.plot(epsilons, mae_values, marker='o')
plt.title('Mean Absolute Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Absolute Error')
plt.xticks(epsilons)

# R^2 Plot
plt.subplot(1, 3, 3)
plt.plot(epsilons, r2_values, marker='o')
plt.title('R^2 Score vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('R^2 Score')
plt.xticks(epsilons)

plt.tight_layout()
plt.show()

import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method

# Preprocess the images
adv_images = [img_preprocess(mpimg.imread(img_path)) for img_path in subset_x_test]
adv_images = np.array(adv_images)

# Generate adversarial examples
epsilon = 0.3  # Perturbation limit
alpha = 0.1  # Small step size for iterative FGSM
num_iterations = 20  # Number of iterations

# Make predictions on the original images
original_preds = model.predict(adv_images)

# Calculate targets: Increase predictions by a certain amount
target = np.clip(original_preds + 0.5, -1, 1)  # Increase steering angle by 0.5

# Custom loss function for regression FGSM
def custom_loss(labels, logits):
    return tf.keras.losses.mean_squared_error(labels, logits)

# Iterative FGSM
for _ in range(num_iterations):
    perturbations = fast_gradient_method(model, adv_images, eps=alpha, norm=np.inf, loss_fn=custom_loss, y=target)
    perturbations = np.clip(perturbations, -alpha, alpha)
    adv_examples = adv_images + perturbations
    adv_examples = tf.clip_by_value(adv_examples, 0, 1)  # Ensure values are between [0, 1]

# Evaluate model on adversarial examples
adv_predictions = model.predict(adv_examples)

# Calculate metrics on adversarial examples
adv_mse = mean_squared_error(subset_y_test, adv_predictions)
adv_mae = mean_absolute_error(subset_y_test, adv_predictions)
adv_r2 = r2_score(subset_y_test, adv_predictions)

print(f'Mean Squared Error on Adversarial Examples: {adv_mse}')
print(f'Mean Absolute Error on Adversarial Examples: {adv_mae}')
print(f'R^2 Score on Adversarial Examples: {adv_r2}')

# Predictions on original images
original_predictions = model.predict(adv_images)

# Visualization of original vs. adversarial examples
num_examples = 5
plt.figure(figsize=(20, num_examples * 6))
for i in range(num_examples):
    # Original image
    plt.subplot(num_examples, 2, i * 2 + 1)
    plt.imshow(adv_images[i])
    plt.title(f'Original Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {original_predictions[i][0]}')

    # Adversarial image
    plt.subplot(num_examples, 2, i * 2 + 2)
    plt.imshow(adv_examples[i])
    plt.title(f'Adversarial Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {adv_predictions[i][0]}')

plt.tight_layout()
plt.show()

epsilons = np.arange(0.1, 0.3, 0.02)  # This will give [0.1, 0.14, 0.18, ... , 0.28]
mse_values = []
mae_values = []
r2_values = []

for eps in epsilons:
    # Generate adversarial examples using FGSM for current epsilon
    perturbations = fast_gradient_method(model, adv_images, eps, np.inf, loss_fn=custom_loss, y=target)
    perturbations = np.clip(perturbations, -eps, eps)
    adv_examples = adv_images + perturbations
    adv_examples = np.clip(adv_examples, 0, 1)

    # Evaluate model on adversarial examples
    adv_predictions = model.predict(adv_examples)

    # Calculate metrics on adversarial examples
    mse_values.append(mean_squared_error(subset_y_test, adv_predictions))
    mae_values.append(mean_absolute_error(subset_y_test, adv_predictions))
    r2_values.append(r2_score(subset_y_test, adv_predictions))

# Plotting
plt.figure(figsize=(15, 5))

# MSE Plot
plt.subplot(1, 3, 1)
plt.plot(epsilons, mse_values, marker='o')
plt.title('Mean Squared Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Squared Error')
plt.xticks(epsilons)

# MAE Plot
plt.subplot(1, 3, 2)
plt.plot(epsilons, mae_values, marker='o')
plt.title('Mean Absolute Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Absolute Error')
plt.xticks(epsilons)

# R^2 Plot
plt.subplot(1, 3, 3)
plt.plot(epsilons, r2_values, marker='o')
plt.title('R^2 Score vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('R^2 Score')
plt.xticks(epsilons)

plt.tight_layout()
plt.show()

import numpy as np
import tensorflow as tf
from tensorflow.keras import backend as K
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method

# Preprocess the images
adv_images = [img_preprocess(mpimg.imread(img_path)) for img_path in subset_x_test]
adv_images = np.array(adv_images)

# Generate adversarial examples
epsilon = 0.2  # Perturbation limit
alpha = 0.1  # Small step size for iterative FGSM
num_iterations = 10  # Number of iterations

# Make predictions on the original images
original_preds = model.predict(adv_images)

# Calculate targets: Increase predictions by a certain amount
target = np.clip(original_preds + 0.5, -1, 1)  # Increase steering angle by 0.5

# Custom loss function for regression FGSM
def custom_loss(labels, logits):
    return tf.keras.losses.mean_squared_error(labels, logits)

# Iterative FGSM
for _ in range(num_iterations):
    perturbations = fast_gradient_method(model, adv_images, eps=alpha, norm=np.inf, loss_fn=custom_loss, y=target)
    perturbations = np.clip(perturbations, -alpha, alpha)
    adv_examples = adv_images + perturbations
    adv_examples = tf.clip_by_value(adv_examples, 0, 1)  # Ensure values are between [0, 1]

# Evaluate model on adversarial examples
adv_predictions = model.predict(adv_examples)

# Calculate metrics on adversarial examples
adv_mse = mean_squared_error(subset_y_test, adv_predictions)
adv_mae = mean_absolute_error(subset_y_test, adv_predictions)
adv_r2 = r2_score(subset_y_test, adv_predictions)

print(f'Mean Squared Error on Adversarial Examples: {adv_mse}')
print(f'Mean Absolute Error on Adversarial Examples: {adv_mae}')
print(f'R^2 Score on Adversarial Examples: {adv_r2}')

# Predictions on original images
original_predictions = model.predict(adv_images)

# Visualization of original vs. adversarial examples
num_examples = 5
plt.figure(figsize=(20, num_examples * 6))
for i in range(num_examples):
    # Original image
    plt.subplot(num_examples, 2, i * 2 + 1)
    plt.imshow(adv_images[i])
    plt.title(f'Original Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {original_predictions[i][0]}')

    # Adversarial image
    plt.subplot(num_examples, 2, i * 2 + 2)
    plt.imshow(adv_examples[i])
    plt.title(f'Adversarial Image\nTrue Steering Angle: {subset_y_test[i]}\nPredicted Steering Angle: {adv_predictions[i][0]}')

plt.tight_layout()
plt.show()

epsilons = np.arange(0.1, 0.3, 0.02)  # This will give [0.1, 0.14, 0.18, ... , 0.28]
mse_values = []
mae_values = []
r2_values = []

for eps in epsilons:
   # Iterative FGSM
  for _ in range(num_iterations):
    perturbations = fast_gradient_method(model, adv_images, eps, norm=np.inf, loss_fn=custom_loss, y=target)
    perturbations = np.clip(perturbations, -alpha, alpha)
    adv_examples = adv_images + perturbations
    adv_examples = tf.clip_by_value(adv_examples, 0, 1)  # Ensure values are between [0, 1]

  # Evaluate model on adversarial examples
  adv_predictions = model.predict(adv_examples)

  # Calculate metrics on adversarial examples
  mse_values.append(mean_squared_error(subset_y_test, adv_predictions))
  mae_values.append(mean_absolute_error(subset_y_test, adv_predictions))
  r2_values.append(r2_score(subset_y_test, adv_predictions))

# Plotting
plt.figure(figsize=(15, 5))

# MSE Plot
plt.subplot(1, 3, 1)
plt.plot(epsilons, mse_values, marker='o')
plt.title('Mean Squared Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Squared Error')
plt.xticks(epsilons)

# MAE Plot
plt.subplot(1, 3, 2)
plt.plot(epsilons, mae_values, marker='o')
plt.title('Mean Absolute Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Absolute Error')
plt.xticks(epsilons)

# R^2 Plot
plt.subplot(1, 3, 3)
plt.plot(epsilons, r2_values, marker='o')
plt.title('R^2 Score vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('R^2 Score')
plt.xticks(epsilons)

plt.tight_layout()
plt.show()

from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent

# Parameters for PGD
epsilon = 0.2
num_steps = 10
step_size = epsilon
clip_min = 0  # Minimum value for each pixel in the generated adversarial example
clip_max = 1  # Maximum value for each pixel in the generated adversarial example

# Custom loss function for regression
def custom_loss(labels, logits):
    return tf.keras.losses.mean_squared_error(labels, logits)

# Generate adversarial examples using PGDadv_examples = projected_gradient_descent(model, adv_images, eps=epsilon, eps_iter=step_size, nb_iter=num_steps, norm=np.inf, loss_fn=custom_loss, clip_min=clip_min, clip_max=clip_max, y=target)
# adv_examples = projected_gradient_descent(model, adv_images, eps=epsilon, eps_iter=step_size, nb_iter=num_steps, norm=np.inf, loss_fn=custom_loss, clip_min=clip_min, clip_max=clip_max, y=target)

perturbations = projected_gradient_descent(model, adv_images, eps=epsilon, eps_iter=step_size, nb_iter=num_steps, norm=np.inf, loss_fn=custom_loss, y=target)
perturbations = np.clip(perturbations, -epsilon, epsilon)
adv_examples = adv_images + perturbations
adv_examples = tf.clip_by_value(adv_examples, 0, 1)

# Evaluate model on adversarial examples
adv_predictions = model.predict(adv_examples)

# Calculate metrics on adversarial examples
adv_mse = mean_squared_error(subset_y_test, adv_predictions)
adv_mae = mean_absolute_error(subset_y_test, adv_predictions)
adv_r2 = r2_score(subset_y_test, adv_predictions)

print(f'Mean Squared Error on Adversarial Examples: {adv_mse}')
print(f'Mean Absolute Error on Adversarial Examples: {adv_mae}')
print(f'R^2 Score on Adversarial Examples: {adv_r2}')

epsilons = np.arange(0.1, 0.3, 0.02)  # This will give [0.1, 0.14, 0.18, ... , 0.28]
mse_values = []
mae_values = []
r2_values = []

for eps in epsilons:
   # Iterative FGSM
  adv_examples = projected_gradient_descent(model, adv_images, eps=eps, eps_iter=step_size, nb_iter=num_steps, norm=np.inf, loss_fn=custom_loss, y=target)

  # Evaluate model on adversarial examples
  adv_predictions = model.predict(adv_examples)

  # Calculate metrics on adversarial examples
  mse_values.append(mean_squared_error(subset_y_test, adv_predictions))
  mae_values.append(mean_absolute_error(subset_y_test, adv_predictions))
  r2_values.append(r2_score(subset_y_test, adv_predictions))

# Plotting
plt.figure(figsize=(15, 5))

# MSE Plot
plt.subplot(1, 3, 1)
plt.plot(epsilons, mse_values, marker='o')
plt.title('Mean Squared Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Squared Error')
plt.xticks(epsilons)

# MAE Plot
plt.subplot(1, 3, 2)
plt.plot(epsilons, mae_values, marker='o')
plt.title('Mean Absolute Error vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('Mean Absolute Error')
plt.xticks(epsilons)

# R^2 Plot
plt.subplot(1, 3, 3)
plt.plot(epsilons, r2_values, marker='o')
plt.title('R^2 Score vs Epsilon')
plt.xlabel('Epsilon')
plt.ylabel('R^2 Score')
plt.xticks(epsilons)

plt.tight_layout()
plt.show()

from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2

# Parameters for C&W attack
batch_size = 1  # Depending on the size of your test data and GPU memory
adv_images = adv_images.astype(np.float32)

confidences = np.arange(5, 25, 5)  # Example confidence values
mse_values = []
mae_values = []
r2_values = []

dummy_input = tf.random.normal(shape=[1, *adv_images.shape[1:]])
_ = model(dummy_input)
model.compile(optimizer='adam', loss='mse')  # Use appropriate optimizer and loss
model.optimizer.build(model.trainable_variables)

for conf in confidences:
    adv_examples_cw = carlini_wagner_l2(model, adv_images, confidence=conf, batch_size=batch_size)

    # Evaluate model on adversarial examples from C&W
    adv_predictions = model.predict(adv_examples_cw)

    # Calculate metrics on adversarial examples
    mse_values.append(mean_squared_error(subset_y_test, adv_predictions))
    mae_values.append(mean_absolute_error(subset_y_test, adv_predictions))
    r2_values.append(r2_score(subset_y_test, adv_predictions))

# Plotting
plt.figure(figsize=(15, 5))

# MSE Plot
plt.subplot(1, 3, 1)
plt.plot(confidences, mse_values, marker='o')
plt.title('Mean Squared Error vs Confidence')
plt.xlabel('Confidence')
plt.ylabel('Mean Squared Error')
plt.xticks(confidences)

# MAE Plot
plt.subplot(1, 3, 2)
plt.plot(confidences, mae_values, marker='o')
plt.title('Mean Absolute Error vs Confidence')
plt.xlabel('Confidence')
plt.ylabel('Mean Absolute Error')
plt.xticks(confidences)

# R^2 Plot
plt.subplot(1, 3, 3)
plt.plot(confidences, r2_values, marker='o')
plt.title('R^2 Score vs Confidence')
plt.xlabel('Confidence')
plt.ylabel('R^2 Score')
plt.xticks(confidences)

plt.tight_layout()
plt.show()


epsilons = np.arange(5, 25, 5)  # This will give [0.1, 0.14, 0.18, ... , 0.28]
mse_values = []
mae_values = []
r2_values = []

# for eps in epsilons:
#    # Iterative FGSM
#   adv_examples_cw = carlini_wagner_l2(model, adv_images, batch_size=eps)

# # Evaluate model on adversarial examples from C&W
#   adv_predictions = model.predict(adv_examples_cw)

#   # Calculate metrics on adversarial examples
#   mse_values.append(mean_squared_error(subset_y_test, adv_predictions))
#   mae_values.append(mean_absolute_error(subset_y_test, adv_predictions))
#   r2_values.append(r2_score(subset_y_test, adv_predictions))

# # Plotting
# plt.figure(figsize=(15, 5))

# # MSE Plot
# plt.subplot(1, 3, 1)
# plt.plot(epsilons, mse_values, marker='o')
# plt.title('Mean Squared Error vs Epsilon')
# plt.xlabel('Epsilon')
# plt.ylabel('Mean Squared Error')
# plt.xticks(epsilons)

# # MAE Plot
# plt.subplot(1, 3, 2)
# plt.plot(epsilons, mae_values, marker='o')
# plt.title('Mean Absolute Error vs Epsilon')
# plt.xlabel('Epsilon')
# plt.ylabel('Mean Absolute Error')
# plt.xticks(epsilons)

# # R^2 Plot
# plt.subplot(1, 3, 3)
# plt.plot(epsilons, r2_values, marker='o')
# plt.title('R^2 Score vs Epsilon')
# plt.xlabel('Epsilon')
# plt.ylabel('R^2 Score')
# plt.xticks(epsilons)

# plt.tight_layout()
# plt.show()

from cleverhans.tf2.attacks import deepfool

# Parameters for DeepFool
num_classes = 1  # Since it's a regression problem
overshoot = 0.02  # Hyperparameter for DeepFool; dictates the perturbation factor
max_iter = 50  # Maximum number of iterations

adv_examples_df = deepfool(model, adv_images, num_classes=num_classes, overshoot=overshoot, max_iter=max_iter)

# Evaluate model on adversarial examples from DeepFool
adv_predictions_df = model.predict(adv_examples_df)

# Calculate metrics on adversarial examples
adv_mse_df = mean_squared_error(subset_y_test, adv_predictions_df)
adv_mae_df = mean_absolute_error(subset_y_test, adv_predictions_df)
adv_r2_df = r2_score(subset_y_test, adv_predictions_df)

print(f'[DeepFool] Mean Squared Error on Adversarial Examples: {adv_mse_df}')
print(f'[DeepFool] Mean Absolute Error on Adversarial Examples: {adv_mae_df}')
print(f'[DeepFool] R^2 Score on Adversarial Examples: {adv_r2_df}')

import tensorflow as tf

def virtual_adversarial_perturbation(data, model, epsilon=1e-2, num_approximation=1):
    # Calculate the original predictions
    pred = model(data)

    # Initialize random perturbation
    d = tf.random.normal(shape=tf.shape(data), dtype=tf.float32)
    d = d / (tf.norm(d, axis=1, keepdims=True) + 1e-14)

    # Iteratively approximate the virtual adversarial perturbation
    for _ in range(num_approximation):
        d_var = tf.Variable(d, dtype=tf.float32, trainable=True)
        perturbed_data = data + d_var
        perturbed_pred = model(perturbed_data)

        # Calculate the KL divergence between the original and perturbed predictions
        kl = tf.reduce_mean(tf.square(pred - perturbed_pred))

        # Calculate gradient of the KL divergence w.r.t the perturbation
        gradient = tf.gradients(kl, [d_var])[0]

        # Update the perturbation
        d = tf.stop_gradient(gradient)
        d = d / (tf.norm(d, axis=1, keepdims=True) + 1e-14)

    perturbation = epsilon * d
    return perturbation

# Generate virtual adversarial perturbation
perturbation = virtual_adversarial_perturbation(adv_images, model)
adv_examples_vat = adv_images + perturbation

# Ensure perturbed images are within [0,1]
adv_examples_vat = tf.clip_by_value(adv_examples_vat, 0, 1)

# Evaluate model on virtual adversarial examples
adv_predictions_vat = model.predict(adv_examples_vat)

# Calculate metrics on virtual adversarial examples
adv_mse_vat = mean_squared_error(subset_y_test, adv_predictions_vat)
adv_mae_vat = mean_absolute_error(subset_y_test, adv_predictions_vat)
adv_r2_vat = r2_score(subset_y_test, adv_predictions_vat)

print(f'[VAT] Mean Squared Error on Adversarial Examples: {adv_mse_vat}')
print(f'[VAT] Mean Absolute Error on Adversarial Examples: {adv_mae_vat}')
print(f'[VAT] R^2 Score on Adversarial Examples: {adv_r2_vat}')